# indata_fa24_final-project
# reflection_milestone1_11-03-2024
For the first milestone of my project, I undertook a detailed examination of the dataset I acquired from the Web of Science. My initial task was to understand the type of information available and determine which data points would be most useful for my analysis and visualization needs. I decided to employ the paper title, authors and their affiliations, citation counts, publication year, and keywords. However, I am open to adjusting this list as the project evolves.

To begin actual data handling, I merged several files downloaded from the Web of Science into a single data frame. I then proceeded to drop columns (i.e., 'Book Authors', 'Book Editors', 'Book Group Authors', 'Book Author Full Names') that were not relevant to my analysis for the tidy dataset. The first analytical step involved visualizing annual publication trends across two significant journals: COMPUTERS IN HUMAN BEHAVIOR (CHB) and INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES (HCS). This analysis revealed that while CHB showed a rising trend in publications until 2016 before stabilizing, HCS maintained a more constant output without significant fluctuations. The standard deviation in yearly publications for CHB was around 230, compared to only 23 for HCS, indicating much greater variability in CHB's publication volume. Initially, I created separate graphs for the total and each journal's publication trends but then integrated these into a single interactive graph using Plotlyâ€™s updatemenus feature, allowing audiences to select which journal trend they wish to view. This step enhanced the user interaction aspect of the visualization. 

For the analysis of the top 30 authors, after extracting and separating individual authors from the aggregated units, I faced a challenge with the lack of detailed affiliation information. I tackled this by parsing the 'addresses' field with regular expressions to extract more detailed information about the authors' affiliations (i.e., institutions and countries). Once I identified the pattern and extracted the affiliations, I matched these details against my list of the top 30 authors to populate their respective information in a new data frame. However, three author data points among the top 30 authors were missing, and I had no idea about the code issues and had to add them manually. The resulting visualization not only displayed the number of publications per author but also color-coded these by the author's country, adding an additional layer of insight.

Moving forward, I used methodologies similar to those used for extracting top author data to also identify the top 30 affiliations and highlight the most influential institutions in the HCI field. Following the affiliations analysis, I extracted the top 50 papers based on citation counts. I employed a color-coding scheme in my visualizations to differentiate papers by the year of publication. This analysis revealed that papers with high citation counts predominantly originated from the period before 2015. I realized the length of time since publication has a significant impact on citation counts and prompted a subsequent analysis focused exclusively on papers published after 2015 to understand how recent publications in terms of impact and citation trends.

In the next step, I plan to extend my analysis to papers published after 2020 to ensure a comprehensive understanding of current and emerging research trends within HCI. This will involve a detailed examination of publication themes. An essential component of my upcoming work will involve an analysis of keywords. Initially, I will compile and analyze keywords from all periods to identify overarching research trends. This will be followed by segmenting the keyword analysis by specific time frames to pinpoint hot topics and shifts in research focus over time. This stratified approach will allow for a nuanced understanding of the evolution of research themes within HCI.


